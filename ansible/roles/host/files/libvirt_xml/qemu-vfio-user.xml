<domain type="kvm" xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0'>
    <name>qemu-vfio-user</name>

    <metadata>
        <libosinfo:libosinfo xmlns:libosinfo="http://libosinfo.org/xmlns/libvirt/domain/1.0">
            <libosinfo:os id="http://ubuntu.com/ubuntu/20.04"/>
        </libosinfo:libosinfo>
    </metadata>

    <memory unit="GiB">16</memory>
    <vcpu cpuset="0-17" placement="static">18</vcpu>

    <os>
        <type arch="x86_64" machine="pc-q35-4.2">hvm</type>
        <boot dev="hd"/>
    </os>

    <features>
        <acpi/>
        <apic/>

        <!-- needed for the viommu -->
        <ioapic driver='qemu'/>
    </features>

    <cpu check="partial" mode="host-model"/>
    <clock offset="utc">
        <timer name="rtc" tickpolicy="catchup"/>
        <timer name="pit" tickpolicy="delay"/>
        <timer name="hpet" present="no"/>
    </clock>

    <pm>
        <suspend-to-mem enabled="no"/>
        <suspend-to-disk enabled="no"/>
    </pm>

    <!-- we need to have the memory be backed by hugepages, according to https://github.com/nutanix/libvfio-user/blob/c08f20634159d977df8f551d07617a8c6b2fea64/docs/spdk.md#libvirt-->
    <memoryBacking>
        <hugepages>
            <page size='2048' unit='KiB'/>
        </hugepages>
        <source type='memfd'/>
        <access mode='shared'/>
    </memoryBacking>

    <!-- disk under test, needs a running nvmf target SPDK server process in the host -->
    <qemu:commandline>
        <qemu:arg value='-device'/>
        <qemu:arg value='vfio-user-pci,socket=/var/run/cntrl,x-enable-migration=on'/>
    </qemu:commandline>

    <devices>
        <!-- multiprocess qemu is the one that works -->
        <emulator>/nutanix-src/qemu-orcl/build/qemu-system-x86_64</emulator>
        
        <!-- os image disk -->
        <disk device="disk" type="file">
            <driver name="qemu" type="qcow2"/>
            <!-- remember to create this disk with qemu-img -->
            <source file="/nvme-fio/bench_server_config/images/qemu-vfio-user.qcow"/>
            <backingStore type="file">
                <format type="qcow2"/>
                <source file="/nvme-fio/bench_server_config/images/jammy-server-cloudimg-amd64.img"/>
                <backingStore/>
            </backingStore>
            <target bus="virtio" dev="sda"/>
        </disk>
        
        <!-- ubuntu cloud image sillyness, gives a default password to the image -->
        <disk device="disk" type="file">
            <source file="/nvme-fio/bench_server_config/images/user-data.img"/>
            <target bus="virtio" dev="sdb"/>
        </disk>
        
        <!-- host/guest folder sharing, the target is a tag that has to be mounted in -->
        <filesystem accessmode="passthrough" type="mount">
            <source dir="/nvme-fio"/>
            <target dir="nvme_fio"/>
        </filesystem>

        <filesystem accessmode="passthrough" type="mount">
            <source dir="/nutanix-src"/>
            <target dir="nutanix_src"/>
        </filesystem>
        
        <!-- internet, needs libvirtd to be restarted while vm is running for iptables to reload -->
        <interface type="network">
            <source network="default"/>
            <model type="virtio"/>
        </interface>

        <!-- we need to enable vfio inside the guest, so we need a virtual iommu https://mcastelino.medium.com/how-to-use-vfio-to-assign-a-device-to-nested-vm-adb943dada4e -->
        <iommu model='intel'>
            <driver intremap='on' caching_mode='on' iotlb="on" />
        </iommu>
        
        <!-- serial console to interact with virsh -->
        <console type="pty"/>
    </devices>
</domain>
